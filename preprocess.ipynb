{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import parselmouth\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "def rpde2(data, m, tau, t):\n",
    "    # Embed the data\n",
    "    data = data[data != 0]\n",
    "    embedded_data = np.array([data[i:i+m*tau:tau] for i in range(len(data) - (m-1)*tau - t + 1)])\n",
    "    \n",
    "    # Calculate the recurrence matrix\n",
    "    dist = pdist(embedded_data, 'chebyshev')\n",
    "    recurrence_matrix = squareform(dist < np.percentile(dist, 20))\n",
    "\n",
    "    # Calculate RPDE\n",
    "    epsilon = 1e-10  # Small constant to avoid taking log2(0)\n",
    "    rpde = -np.sum(recurrence_matrix * np.log2(recurrence_matrix + epsilon)) / np.sum(recurrence_matrix)\n",
    "\n",
    "    return rpde\n",
    "\n",
    "def grassberger_procaccia(data, m, r):\n",
    "    def _maxdist(x_i, x_j):\n",
    "        return max([abs(ua - va) for ua, va in zip(x_i, x_j)])\n",
    "\n",
    "    def _phi(m):\n",
    "        x = [[data[j] for j in range(i, i + m - 1 + 1)] for i in range(N - m + 1)]\n",
    "        C = [len([1 for x_j in x if _maxdist(x_i, x_j) <= r]) / (N - m + 1.0) for x_i in x]\n",
    "        return (N - m + 1.0)**(-1) * sum(np.log(C))\n",
    "\n",
    "    N = len(data)\n",
    "    return abs(_phi(m+1) - _phi(m))\n",
    "\n",
    "def extract_audio_features(fileName):\n",
    "    \n",
    "    features = {}\n",
    "\n",
    "    # Load the audio file\n",
    "    audio, sr = librosa.load(fileName)\n",
    "    # Load the audio file\n",
    "    snd = parselmouth.Sound(fileName)\n",
    "\n",
    "    # Calculate the fundamental frequency\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(audio, fmin=75, fmax=600)\n",
    "    valid_f0 = f0[~np.isnan(f0)]\n",
    "\n",
    "    # Compute the average fundamental frequency\n",
    "    average_f0 = valid_f0.mean()\n",
    "    max_f0 = np.max(valid_f0)\n",
    "    min_f0 = np.min(valid_f0)\n",
    "    jitter_percent = (np.std(valid_f0) / np.mean(valid_f0)) * 100\n",
    "    jitter_absolute = np.mean(np.abs(np.diff(valid_f0)))\n",
    "    rap = np.mean(np.abs(np.diff(valid_f0)))\n",
    "    ppq = np.mean(np.abs(np.diff(valid_f0, n=2)))\n",
    "    \n",
    "    \n",
    "    features['average_f0'] = average_f0\n",
    "    features['max_f0'] = max_f0\n",
    "    features['min_f0'] = min_f0\n",
    "    features['jitter_percent'] = jitter_percent\n",
    "    features['jitter_absolute'] = jitter_absolute\n",
    "    features['rap'] = rap\n",
    "    features['ppq'] = ppq\n",
    "    \n",
    "    # Calculate the amplitude envelope\n",
    "    amplitude_envelope = np.abs(librosa.effects.hpss(audio)[0])\n",
    "\n",
    "    # Compute the time array for the amplitude envelope\n",
    "    time = np.arange(len(amplitude_envelope)) / sr\n",
    "\n",
    "    shimmer_apq3 = np.mean(np.abs(np.diff(amplitude_envelope, n=3)))\n",
    "    shimmer_apq5 = np.mean(np.abs(np.diff(amplitude_envelope, n=5)))\n",
    "    mdvp_shimmer = np.mean(np.abs(np.diff(amplitude_envelope)))\n",
    "    mdvp_shimmer_db = 20 * np.log10(np.mean(np.abs(np.diff(amplitude_envelope))))\n",
    "    jitter_ddp = np.mean(np.abs(np.diff(np.diff(amplitude_envelope))))\n",
    "    mdvp_apq = np.mean(np.square(np.diff(amplitude_envelope, n=2)))\n",
    "    shimmer_dda = np.mean(np.abs(np.diff(amplitude_envelope))) / (np.max(amplitude_envelope) - np.min(amplitude_envelope))\n",
    "    harmonic_energy = np.mean(amplitude_envelope ** 2)\n",
    "    noise_energy = np.mean((audio - amplitude_envelope) ** 2)\n",
    "    nhr = noise_energy / harmonic_energy\n",
    "    hnr = harmonic_energy / noise_energy\n",
    "    \n",
    "    features['shimmer_apq3'] = shimmer_apq3\n",
    "    features['shimmer_apq5'] = shimmer_apq5\n",
    "    features['mdvp_shimmer'] = mdvp_shimmer\n",
    "    features['mdvp_shimmer_db'] = mdvp_shimmer_db\n",
    "    features['jitter_ddp'] = jitter_ddp\n",
    "    features['mdvp_apq'] = mdvp_apq\n",
    "    features['shimmer_dda'] = shimmer_dda\n",
    "    features['nhr'] = nhr\n",
    "    features['hnr'] = hnr\n",
    "    \t\n",
    "    # print(\"Average vocal fundamental frequency (MDVP:Fo):\", average_f0, \"Hz\")\n",
    "    # print(\"Maximum vocal fundamental frequency (MDVP:Fhi):\", max_f0, \"Hz\")\n",
    "    # print(\"Minimum vocal fundamental frequency (MDVP:Flo):\", min_f0, \"Hz\")\n",
    "    # Compute the MDVP:Jitter (Abs)\n",
    "    # print(\"MDVP:Jitter (%):\", jitter_percent)\n",
    "    # print(\"MDVP:Jitter (Abs):\", jitter_absolute)\n",
    "    # Compute the MDVP:PPQ (Five measures of variation in fundamental frequency)\n",
    "    # print(\"MDVP:RAP:\", rap)\n",
    "    # print(\"MDVP:PPQ:\", ppq)\n",
    "    \n",
    "    # print(\"Jitter:DDP:\", jitter_ddp)\n",
    "    # print(\"MDVP:Shimmer:\", mdvp_shimmer)\n",
    "    # print(\"MDVP:Shimmer (dB):\", mdvp_shimmer_db)\n",
    "    # print(\"Shimmer:APQ3:\", shimmer_apq3)\n",
    "    # print(\"Shimmer:APQ5:\", shimmer_apq5)\n",
    "    # print(\"MDVP:APQ:\", mdvp_apq)\n",
    "    # print(\"Shimmer:DDA:\", shimmer_dda)\n",
    "    # print(\"NHR:\", nhr)\n",
    "    # print(\"HNR:\", hnr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Extract fundamental frequency (F0) contour\n",
    "    pitch = snd.to_pitch()\n",
    "    unit = \"Hertz\"  # or \"Mel\", \"LogHertz\", \"ERB\", \"Semitones\", \"Bark\", depending on your needs\n",
    "\n",
    "    # Define time range\n",
    "    start_time = 0.0  # start of the sound\n",
    "    end_time = snd.get_total_duration()  # end of the sound\n",
    "\n",
    "    # Use the defined time and quantile range\n",
    "    spread1 = parselmouth.praat.call(pitch, \"Get quantile\", start_time, end_time, 0.75, unit) - parselmouth.praat.call(pitch, \"Get quantile\", start_time, end_time, 0.25, unit)\n",
    "    spread2 = parselmouth.praat.call(pitch, \"Get quantile\", start_time, end_time, 0.90, unit) - parselmouth.praat.call(pitch, \"Get quantile\", start_time, end_time, 0.10, unit)\n",
    "\n",
    "\n",
    "    # Convert Pitch object to PointProcess object\n",
    "    pointProcess = parselmouth.praat.call(pitch, \"To PointProcess\")\n",
    "    # Get the number of points\n",
    "    num_points = parselmouth.praat.call(pointProcess, \"Get number of points\")\n",
    "    # Get the intervals\n",
    "    intervals = [parselmouth.praat.call(pointProcess, \"Get time from index\", i+1) - parselmouth.praat.call(pointProcess, \"Get time from index\", i) for i in range(1, num_points)]\n",
    "    # Calculate the probabilities\n",
    "    probabilities = np.bincount(intervals) / len(intervals)\n",
    "    # Calculate the entropy\n",
    "    ppe = -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "    features['spread1'] = spread1\n",
    "    features['spread2'] = spread2\n",
    "    features['ppe'] = ppe\n",
    "\n",
    "    # print(\"spread1:\", spread1)\n",
    "    # print(\"spread2:\", spread2)\n",
    "    # print(\"PPE (Pitch Period Entropy):\", ppe)\n",
    "    # Convert Pitch object to numpy array\n",
    "    pitch_values = pitch.selected_array['frequency']\n",
    "\n",
    "    # Calculate RPDE\n",
    "    rpde = rpde2(pitch_values, m=2, tau=1, t=1)\n",
    "\n",
    "    # Calculate D2\n",
    "    d2 = grassberger_procaccia(pitch_values, m=2, r=0.2 * np.std(pitch_values))\n",
    "\n",
    "    features['rpde'] = rpde\n",
    "    features['d2'] = d2\n",
    "    \n",
    "    return features\n",
    "\n",
    "headers = ['Person', 'Wav file', 'average_f0', 'max_f0', 'min_f0', 'jitter_percent', 'jitter_absolute', 'rap', 'ppq', 'shimmer_apq3', 'shimmer_apq5', 'mdvp_shimmer', 'mdvp_shimmer_db', 'jitter_ddp', 'mdvp_apq', 'shimmer_dda', 'nhr', 'hnr', 'spread1', 'spread2', 'ppe', 'rpde', 'd2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn audio to CSV\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the root directory containing the audio files\n",
    "root_directory = \"/home/pratik/Desktop/Plaksha_Docs/Semester_4/MLPR/Projects/Italian Parkinson's Voice and speech/28 People with Parkinson's disease\"\n",
    "\n",
    "# Initialize an empty list to store all extracted features\n",
    "all_features = []\n",
    "\n",
    "# Iterate over all subdirectories and WAV files\n",
    "for person_folder in os.listdir(root_directory):\n",
    "    person_folder_path = os.path.join(root_directory, person_folder)\n",
    "    if os.path.isdir(person_folder_path):\n",
    "        for wav_file in os.listdir(person_folder_path):\n",
    "            if wav_file.endswith('.wav'):\n",
    "                wav_file_path = os.path.join(person_folder_path, wav_file)\n",
    "                # Extract features from the current WAV file\n",
    "                features = extract_audio_features(wav_file_path)\n",
    "                # Append the extracted features along with the filename and person's name\n",
    "                all_features.append([person_folder, wav_file] + list(features.values()))\n",
    "\n",
    "# Convert the list of features to a pandas DataFrame\n",
    "df = pd.DataFrame(all_features, columns=headers)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "csv_file_path = \"28 People with Parkinson's disease.csv\"\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Audio analysis results saved to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the root directory containing the audio files\n",
    "root_directory = \"/home/pratik/Desktop/Plaksha_Docs/Semester_4/MLPR/Projects/Italian Parkinson's Voice and speech/22 Elderly Healthy Control\"\n",
    "\n",
    "# Initialize an empty list to store all extracted features\n",
    "all_features = []\n",
    "\n",
    "# Iterate over all subdirectories and WAV files\n",
    "for person_folder in os.listdir(root_directory):\n",
    "    person_folder_path = os.path.join(root_directory, person_folder)\n",
    "    if os.path.isdir(person_folder_path):\n",
    "        for wav_file in os.listdir(person_folder_path):\n",
    "            if wav_file.endswith('.wav'):\n",
    "                wav_file_path = os.path.join(person_folder_path, wav_file)\n",
    "                # Extract features from the current WAV file\n",
    "                features = extract_audio_features(wav_file_path)\n",
    "                # Append the extracted features along with the filename and person's name\n",
    "                all_features.append([person_folder, wav_file] + list(features.values()))\n",
    "\n",
    "# Convert the list of features to a pandas DataFrame\n",
    "df = pd.DataFrame(all_features, columns=headers)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "csv_file_path = 'audio_analysis_results.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Audio analysis results saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize kaggle data\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"parkinsons_fold.csv\")\n",
    "\n",
    "# Normalize numerical columns except 'Person' and 'Wav file'\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numeric_cols] = df[numeric_cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()) if x.name not in ['Person', 'Wav file', 'status', 'rep'] else x)\n",
    "\n",
    "# Write the normalized data back to a new CSV file\n",
    "df.to_csv('normalized_english_kaggle.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the two CSV files\n",
    "df1 = pd.read_csv('normalized_english_kaggle.csv')\n",
    "df2 = pd.read_csv('combined_file_italian.csv')\n",
    "\n",
    "# Ensure columns are in the same order\n",
    "df2 = df2[df1.columns]\n",
    "\n",
    "# Concatenate the two dataframes vertically\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Write the combined data to a new CSV file\n",
    "combined_df.to_csv('final_Data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
