{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import wave\n",
    "import scipy\n",
    "import librosa\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from pydub.utils import db_to_float\n",
    "from pydub.silence import split_on_silence\n",
    "from pydub.silence import detect_silence\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "fileName = \"/home/pratik/Desktop/Plaksha_Docs/Semester_4/MLPR/Projects/Italian Parkinson's Voice and speech/22 Elderly Healthy Control/AGNESE P/VU2APGANRET55F170320171112.wav\"\n",
    "data, sampling_rate  = librosa.core.load(fileName)\n",
    "# Duration : Total duration of the audio\n",
    "total_samples = data.size\n",
    "total_duration = int(total_samples/sampling_rate)\n",
    "# Fourier Transform from data\n",
    "\n",
    "fourier_transform = np.fft.rfft(data)\n",
    "\n",
    "# Frequencies\n",
    "\n",
    "frequencies = np.abs(fourier_transform)\n",
    "\n",
    "# Maximum Pitch\n",
    "\n",
    "max_pitch = np.argmax(frequencies)\n",
    "\n",
    "arr = [117]*len(frequencies)\n",
    "\n",
    "sum_freq = 0\n",
    "\n",
    "for i in range(0,len(frequencies)):\n",
    "    if int(frequencies[i])>0 and int(frequencies[i])<int(max_pitch):\n",
    "        arr[i] = int(frequencies[i])\n",
    "        sum_freq=sum_freq + i\n",
    "        \n",
    "# Minmum Pitch\n",
    "min_pitch = arr.index(min(arr))\n",
    "\n",
    "# Mean pitch\n",
    "mean_pitch=sum_freq/len(frequencies)\n",
    "\n",
    "\n",
    "#total energy\n",
    "energy= np.sum(data**2)\n",
    "energy_freq = np.sum(frequencies**2)/total_samples\n",
    "#power\n",
    "power = energy / total_duration\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(1, figsize=(9,6))\n",
    "# plt.subplot(211)\n",
    "# #IntensityMin : Minimum Intensity of the audio signal\n",
    "# Pxx, freqs, bins, im = plt.specgram(data, Fs = sampling_rate, NFFT=1024, cmap=plt.get_cmap('autumn_r'))\n",
    "# col_bar=plt.colorbar(im)\n",
    "# plt.xlabel('Time (s)')\n",
    "# plt.ylabel('Frequency (Hz)')\n",
    "# col_bar.set_label('Intensity dB')\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #minimum intensity\n",
    "# min_intensity = col_bar.vmin\n",
    "# min_intensity\n",
    "\n",
    "# #maximum intensity\n",
    "# max_intensity = col_bar.vmax\n",
    "# max_intensity\n",
    "\n",
    "# #mean intensity\n",
    "# mean_intensity = (min_intensity + max_intensity) / 2\n",
    "# mean_intensity\n",
    "\n",
    "# sound = AudioSegment.from_wav(\"/home/pratik/Desktop/Plaksha_Docs/Semester_4/MLPR/Projects/Italian Parkinson's Voice and speech/22 Elderly Healthy Control/AGNESE P/VU2APGANRET55F170320171112.wav\")\n",
    "# len(sound)\n",
    "\n",
    "# chunks = split_on_silence(sound,\n",
    "#     # must be silent for at least half a second\n",
    "#     min_silence_len=20,\n",
    "\n",
    "#     # consider it silent if quieter than -16 dBFS\n",
    "#     silence_thresh=-(round(abs(sound.dBFS))+100)\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# #1000 means 1 sec then 60 second means\n",
    "# sixty_seconds = 60 * 1000\n",
    "\n",
    "# second_1_minute = sound[sixty_seconds:120000]\n",
    "# hunks = split_on_silence(second_1_minute,\n",
    "#     # must be silent for at least half a second\n",
    "#     min_silence_len=20,\n",
    "\n",
    "#     # consider it silent if quieter than -16 dBFS\n",
    "#     silence_thresh=-(round(abs(sound.dBFS))+100)\n",
    "# )\n",
    "\n",
    "# #SPEAKING RATE\n",
    "# speaking_rate=len(hunks)/len(chunks)\n",
    "\n",
    "# #SILENCES\n",
    "# pauses=detect_silence(sound, min_silence_len=20, silence_thresh=-(round(abs(sound.dBFS))+100), seek_step=1)\n",
    "\n",
    "# #FINDING DURATIONS\n",
    "# sumd=0\n",
    "# ls=[]\n",
    "# for start_i, end_i in pauses:\n",
    "#          dur=int(end_i)-int(start_i)\n",
    "#          ls.append(dur)\n",
    "# breaks=[]\n",
    "\n",
    "# #VOICE BREAKS\n",
    "# for i in ls:\n",
    "#     if i >900:\n",
    "#         breaks.append(i)\n",
    "# #SEPRATING BREAKES AND PAUSES\n",
    "# ls=list(set(ls)-set(breaks))\n",
    "\n",
    "\n",
    "# #PUASES DURATION\n",
    "# for i in ls:\n",
    "#     sumd=sumd+i\n",
    "    \n",
    "# #NO OF VOICE BREAKES\n",
    "# noofVoiceBreaks=len(breaks)\n",
    "\n",
    "# #FINDING PEAK\n",
    "# peak=scipy.signal.find_peaks(data,rel_height=0.5)\n",
    "\n",
    "# #MAXIMUM FALLING AND MAXIMUM RISING\n",
    "\n",
    "# MaxFalling=np.amin(data)\n",
    "# MaxRising=np.amax(peak[0])\n",
    "# sums=0\n",
    "\n",
    "\n",
    "# #JITTER, SHIMMER, JITTERRAP\n",
    "# for i in range(1,len(peak[0])-1):\n",
    "#     sums=sums+abs(20*math.log10(peak[0][i+1]/peak[0][i]))\n",
    "\n",
    "# #SHIMMER\n",
    "# shimmer=sums/(len(peak[0])-1)\n",
    "# peakf=abs(np.fft.fft(peak[0]))\n",
    "# sumps=0\n",
    "# for i in range(1,len(peakf)-1):\n",
    "#     sumps=sumps+(peakf[i+1]**-1)-(peakf[i]**-1)\n",
    "\n",
    "# #JITTER\n",
    "# jitter=sumps/(len(peakf)-1)\n",
    "# sortedp=np.sort(peak[0])\n",
    "# sortedf=abs(np.fft.fft(sortedp))\n",
    "# dif=abs(sortedp[11]-sortedp[15])\n",
    "# suh=0\n",
    "# avgabsdiff=(dif)/4\n",
    "# avgneigh1=(abs(sortedp[6]-sortedp[10]))\n",
    "# avgneigh2=abs(sortedp[17]-sortedp[22])\n",
    "# avg=(dif+avgneigh1+avgneigh2)/3\n",
    "\n",
    "# for i in range(11,16):\n",
    "#     suh=suh+abs(sortedf[i]**-1)\n",
    "# period=suh/5\n",
    "\n",
    "# #JITTERRAP\n",
    "# jitterrap=(avgabsdiff+avg)/period\n",
    "\n",
    "\n",
    "# #NUMBER OF RISING, NUMBER OF FALLING, AVERAGE RISE, AVERAGE FALL\n",
    "\n",
    "# noofrise=len(peak[0])\n",
    "\n",
    "# avgtorise=noofrise/len(data)\n",
    "# nooffall=0\n",
    "# for i in data:\n",
    "#     if i == np.amin(data):\n",
    "#         nooffall=nooffall+1\n",
    "\n",
    "# avgtofall=nooffall/len(data)\n",
    "\n",
    "\n",
    "# print(\"duration: \"+str(total_duration)+\"seconds\\n\")\n",
    "\n",
    "\n",
    "# print(\"intensityMin: \"+str(min_intensity)+\"dB\\n\")\n",
    "# print(\"intensityMax: \"+str(max_intensity)+\"dB\\n\")\n",
    "# print(\"intensityMean: \"+str(mean_intensity)+\"dB\\n\")\n",
    "# print(\"jitter: \"+str(jitter)+\"\\n\")\n",
    "# print(\"shimmer: \"+str(shimmer)+\"dB\\n\")\n",
    "\n",
    "# print(\"speakRate: \"+str(speaking_rate)+\"wpm\\n\")\n",
    "# # \n",
    "\n",
    "# print(\"Engaging tone: \"+str(MaxFalling)+\"\\n\")\n",
    "\n",
    "# print(\"NOT Stressed: \"+str(avgtofall)+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import parselmouth\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "def rpde2(data, m, tau, t):\n",
    "    # Embed the data\n",
    "    data = data[data != 0]\n",
    "    embedded_data = np.array([data[i:i+m*tau:tau] for i in range(len(data) - (m-1)*tau - t + 1)])\n",
    "    \n",
    "    # Calculate the recurrence matrix\n",
    "    dist = pdist(embedded_data, 'chebyshev')\n",
    "    recurrence_matrix = squareform(dist < np.percentile(dist, 20))\n",
    "\n",
    "    # Calculate RPDE\n",
    "    epsilon = 1e-10  # Small constant to avoid taking log2(0)\n",
    "    rpde = -np.sum(recurrence_matrix * np.log2(recurrence_matrix + epsilon)) / np.sum(recurrence_matrix)\n",
    "\n",
    "    return rpde\n",
    "\n",
    "def grassberger_procaccia(data, m, r):\n",
    "    def _maxdist(x_i, x_j):\n",
    "        return max([abs(ua - va) for ua, va in zip(x_i, x_j)])\n",
    "\n",
    "    def _phi(m):\n",
    "        x = [[data[j] for j in range(i, i + m - 1 + 1)] for i in range(N - m + 1)]\n",
    "        C = [len([1 for x_j in x if _maxdist(x_i, x_j) <= r]) / (N - m + 1.0) for x_i in x]\n",
    "        return (N - m + 1.0)**(-1) * sum(np.log(C))\n",
    "\n",
    "    N = len(data)\n",
    "    return abs(_phi(m+1) - _phi(m))\n",
    "\n",
    "def extract_audio_features(fileName):\n",
    "    \n",
    "    features = {}\n",
    "\n",
    "    # Load the audio file\n",
    "    audio, sr = librosa.load(fileName)\n",
    "    # Load the audio file\n",
    "    snd = parselmouth.Sound(fileName)\n",
    "\n",
    "    # Calculate the fundamental frequency\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(audio, fmin=75, fmax=600)\n",
    "    valid_f0 = f0[~np.isnan(f0)]\n",
    "\n",
    "    # Compute the average fundamental frequency\n",
    "    average_f0 = valid_f0.mean()\n",
    "    max_f0 = np.max(valid_f0)\n",
    "    min_f0 = np.min(valid_f0)\n",
    "    jitter_percent = (np.std(valid_f0) / np.mean(valid_f0)) * 100\n",
    "    jitter_absolute = np.mean(np.abs(np.diff(valid_f0)))\n",
    "    rap = np.mean(np.abs(np.diff(valid_f0)))\n",
    "    ppq = np.mean(np.abs(np.diff(valid_f0, n=2)))\n",
    "    \n",
    "    \n",
    "    features['average_f0'] = average_f0\n",
    "    features['max_f0'] = max_f0\n",
    "    features['min_f0'] = min_f0\n",
    "    features['jitter_percent'] = jitter_percent\n",
    "    features['jitter_absolute'] = jitter_absolute\n",
    "    features['rap'] = rap\n",
    "    features['ppq'] = ppq\n",
    "    \n",
    "    # Calculate the amplitude envelope\n",
    "    amplitude_envelope = np.abs(librosa.effects.hpss(audio)[0])\n",
    "\n",
    "    # Compute the time array for the amplitude envelope\n",
    "    time = np.arange(len(amplitude_envelope)) / sr\n",
    "\n",
    "    shimmer_apq3 = np.mean(np.abs(np.diff(amplitude_envelope, n=3)))\n",
    "    shimmer_apq5 = np.mean(np.abs(np.diff(amplitude_envelope, n=5)))\n",
    "    mdvp_shimmer = np.mean(np.abs(np.diff(amplitude_envelope)))\n",
    "    mdvp_shimmer_db = 20 * np.log10(np.mean(np.abs(np.diff(amplitude_envelope))))\n",
    "    jitter_ddp = np.mean(np.abs(np.diff(np.diff(amplitude_envelope))))\n",
    "    mdvp_apq = np.mean(np.square(np.diff(amplitude_envelope, n=2)))\n",
    "    shimmer_dda = np.mean(np.abs(np.diff(amplitude_envelope))) / (np.max(amplitude_envelope) - np.min(amplitude_envelope))\n",
    "    harmonic_energy = np.mean(amplitude_envelope ** 2)\n",
    "    noise_energy = np.mean((audio - amplitude_envelope) ** 2)\n",
    "    nhr = noise_energy / harmonic_energy\n",
    "    hnr = harmonic_energy / noise_energy\n",
    "    \n",
    "    features['shimmer_apq3'] = shimmer_apq3\n",
    "    features['shimmer_apq5'] = shimmer_apq5\n",
    "    features['mdvp_shimmer'] = mdvp_shimmer\n",
    "    features['mdvp_shimmer_db'] = mdvp_shimmer_db\n",
    "    features['jitter_ddp'] = jitter_ddp\n",
    "    features['mdvp_apq'] = mdvp_apq\n",
    "    features['shimmer_dda'] = shimmer_dda\n",
    "    features['nhr'] = nhr\n",
    "    features['hnr'] = hnr\n",
    "    \t\n",
    "    # print(\"Average vocal fundamental frequency (MDVP:Fo):\", average_f0, \"Hz\")\n",
    "    # print(\"Maximum vocal fundamental frequency (MDVP:Fhi):\", max_f0, \"Hz\")\n",
    "    # print(\"Minimum vocal fundamental frequency (MDVP:Flo):\", min_f0, \"Hz\")\n",
    "    # Compute the MDVP:Jitter (Abs)\n",
    "    # print(\"MDVP:Jitter (%):\", jitter_percent)\n",
    "    # print(\"MDVP:Jitter (Abs):\", jitter_absolute)\n",
    "    # Compute the MDVP:PPQ (Five measures of variation in fundamental frequency)\n",
    "    # print(\"MDVP:RAP:\", rap)\n",
    "    # print(\"MDVP:PPQ:\", ppq)\n",
    "    \n",
    "    # print(\"Jitter:DDP:\", jitter_ddp)\n",
    "    # print(\"MDVP:Shimmer:\", mdvp_shimmer)\n",
    "    # print(\"MDVP:Shimmer (dB):\", mdvp_shimmer_db)\n",
    "    # print(\"Shimmer:APQ3:\", shimmer_apq3)\n",
    "    # print(\"Shimmer:APQ5:\", shimmer_apq5)\n",
    "    # print(\"MDVP:APQ:\", mdvp_apq)\n",
    "    # print(\"Shimmer:DDA:\", shimmer_dda)\n",
    "    # print(\"NHR:\", nhr)\n",
    "    # print(\"HNR:\", hnr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Extract fundamental frequency (F0) contour\n",
    "    pitch = snd.to_pitch()\n",
    "    unit = \"Hertz\"  # or \"Mel\", \"LogHertz\", \"ERB\", \"Semitones\", \"Bark\", depending on your needs\n",
    "\n",
    "    # Define time range\n",
    "    start_time = 0.0  # start of the sound\n",
    "    end_time = snd.get_total_duration()  # end of the sound\n",
    "\n",
    "    # Use the defined time and quantile range\n",
    "    spread1 = parselmouth.praat.call(pitch, \"Get quantile\", start_time, end_time, 0.75, unit) - parselmouth.praat.call(pitch, \"Get quantile\", start_time, end_time, 0.25, unit)\n",
    "    spread2 = parselmouth.praat.call(pitch, \"Get quantile\", start_time, end_time, 0.90, unit) - parselmouth.praat.call(pitch, \"Get quantile\", start_time, end_time, 0.10, unit)\n",
    "\n",
    "\n",
    "    # Convert Pitch object to PointProcess object\n",
    "    pointProcess = parselmouth.praat.call(pitch, \"To PointProcess\")\n",
    "    # Get the number of points\n",
    "    num_points = parselmouth.praat.call(pointProcess, \"Get number of points\")\n",
    "    # Get the intervals\n",
    "    intervals = [parselmouth.praat.call(pointProcess, \"Get time from index\", i+1) - parselmouth.praat.call(pointProcess, \"Get time from index\", i) for i in range(1, num_points)]\n",
    "    # Calculate the probabilities\n",
    "    probabilities = np.bincount(intervals) / len(intervals)\n",
    "    # Calculate the entropy\n",
    "    ppe = -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "    features['spread1'] = spread1\n",
    "    features['spread2'] = spread2\n",
    "    features['ppe'] = ppe\n",
    "\n",
    "    # print(\"spread1:\", spread1)\n",
    "    # print(\"spread2:\", spread2)\n",
    "    # print(\"PPE (Pitch Period Entropy):\", ppe)\n",
    "    # Convert Pitch object to numpy array\n",
    "    pitch_values = pitch.selected_array['frequency']\n",
    "\n",
    "    # Calculate RPDE\n",
    "    rpde = rpde2(pitch_values, m=2, tau=1, t=1)\n",
    "\n",
    "    # Calculate D2\n",
    "    d2 = grassberger_procaccia(pitch_values, m=2, r=0.2 * np.std(pitch_values))\n",
    "\n",
    "    features['rpde'] = rpde\n",
    "    features['d2'] = d2\n",
    "    # print(\"RPDE:\", rpde)\n",
    "    # print(\"D2:\", d2)\n",
    "    \n",
    "    return features\n",
    "\n",
    "headers = ['Person', 'Wav file', 'average_f0', 'max_f0', 'min_f0', 'jitter_percent', 'jitter_absolute', 'rap', 'ppq', 'shimmer_apq3', 'shimmer_apq5', 'mdvp_shimmer', 'mdvp_shimmer_db', 'jitter_ddp', 'mdvp_apq', 'shimmer_dda', 'nhr', 'hnr', 'spread1', 'spread2', 'ppe', 'rpde', 'd2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio analysis results saved to audio_analysis_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the root directory containing the audio files\n",
    "root_directory = \"/home/pratik/Desktop/Plaksha_Docs/Semester_4/MLPR/Projects/Italian Parkinson's Voice and speech/22 Elderly Healthy Control\"\n",
    "\n",
    "# Initialize an empty list to store all extracted features\n",
    "all_features = []\n",
    "\n",
    "# Iterate over all subdirectories and WAV files\n",
    "for person_folder in os.listdir(root_directory):\n",
    "    person_folder_path = os.path.join(root_directory, person_folder)\n",
    "    if os.path.isdir(person_folder_path):\n",
    "        for wav_file in os.listdir(person_folder_path):\n",
    "            if wav_file.endswith('.wav'):\n",
    "                wav_file_path = os.path.join(person_folder_path, wav_file)\n",
    "                # Extract features from the current WAV file\n",
    "                features = extract_audio_features(wav_file_path)\n",
    "                # Append the extracted features along with the filename and person's name\n",
    "                all_features.append([person_folder, wav_file] + list(features.values()))\n",
    "\n",
    "# Convert the list of features to a pandas DataFrame\n",
    "df = pd.DataFrame(all_features, columns=headers)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "csv_file_path = 'audio_analysis_results.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Audio analysis results saved to {csv_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
